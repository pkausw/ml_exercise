{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3227754d",
   "metadata": {},
   "source": [
    "# **Exercises 7:** Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a0df1",
   "metadata": {},
   "source": [
    "In this exercise sheet, we will study and train neural networks (NN). We are going to apply some common machine\n",
    "learning methods to a particle physics task: the separation of jets originating from top quarks from jets originating\n",
    "from gluons in events recorded by the ATLAS detector.\n",
    "\n",
    "This exercise was adapted from a [previous exercise](https://github.com/dkgithub/wuhan_DL_labs/tree/master/top-tagging)\n",
    "with courtesy from Lisa Benato. The data used in this exercise was provided by\n",
    "[Gregor Kasieczka et al](https://arxiv.org/abs/1902.09914).\n",
    "\n",
    "Work on that exercise sheet by using the [UHH Jupyter server](https://code.min.uni-hamburg.de/). Login\n",
    "with your UHH credentials (your account with username `bXXXX`).\n",
    "The default image includes all packages that are required for executing the code. This notebook has been tested with\n",
    "*Python 3.11.2* and *Tensorflow 2.18*.\n",
    "\n",
    "The code for that exercise sheet as well as the instructions have been prepared in a *Jupyter* notebook. You can \n",
    "retrieve the exercise material (notebook, data and exercise sheet) using `git`. For that follow these steps:\n",
    "\n",
    "- If you haven't done yet clone the repository. Login to the *UHH Jupyter Machine*. Go to the folder where you want\n",
    "  to place the new repository. Select *Git > Clone a Repository* in the toolbar on the top of the *Jupyter Lab* web\n",
    "  interface. Now a dialog that asks for a web address should open. Enter the URL\n",
    "  [https://github.com/pkausw/ml_exercise.git](https://github.com/pkausw/ml_exercise.git) of the exercise.\n",
    "\n",
    "  After having pressed the *Clone* button the download of the repository starts. A new folder with the name of\n",
    "  the repository should appear in the file browser sidebar.\n",
    "\n",
    "- To update the repository contents go to the repository folder that you have cloned. For retrieving the recent version\n",
    "  of the repository go to *Git > Pull from Remote* in the toolbar on the top of the *Jupyter Lab* web interface.\n",
    "\n",
    "- Next, copy the input data for this exercise to the machine. For this, open a new terminal by clicking on the *+* sign at the top of this window and select *Other > Terminal*. Execute the following command: \n",
    "`wget https://syncandshare.desy.de/index.php/s/rKrtHqbQwb5TAfg/download -O dataset.zip`. This will create the file `dataset.zip` in your current working directory.\n",
    "\n",
    "- Unpack this new file with `unzip dataset.zip`. You will now see the directory `wuhan_data`.\n",
    "\n",
    "- Move the data to the correct location. Assuming you are still in the same directory into which you cloned the `ml_exercise` repository, the command is `mv wuhan_data/top-tagging ml_exercise/data`\n",
    "\n",
    "- In order to read this data, we need to install one final python package. Execute `pip install tables`.\n",
    "\n",
    "You are now all set up for the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a76828",
   "metadata": {},
   "source": [
    "## 1. Top tagging using deep neural networks\n",
    "\n",
    "We want to separate jets that originate from top quarks from jets that originate from gluons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f23d1b",
   "metadata": {},
   "source": [
    "- **Task 1.1.** What is the difference between jets originating from top quarks and gluons?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa430ca",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c22927",
   "metadata": {},
   "source": [
    "The separation of these jets is a difficult task and will be explained in the lecture. In this exercise we train a\n",
    "*deep neural network* (DNN) for classifying jets. The DNN is trained with kinematic information of these jets. In\n",
    "that way it learns to differentiate between jets as originating from a top quark or a gluon. This is a supervised\n",
    "learning approach where we need labeled data to train the classifier.\n",
    "\n",
    "In our case, we use jets produced with the Pythia8 parton shower for a center-of-mass energy of 14 TeV. The detector\n",
    "response is simulated using Delphes simulating the ATLAS detector. The jets are clustered as fat jets using the\n",
    "anti-$k_{\\mathrm{T}}$ algorithm with a radius parameter of $R = 0.8$ (called *AK8-jets*). Jets are only considered in a\n",
    "$p_{\\mathrm{T}}$ range of $[550 - 650]\\,\\mathrm{GeV}$.\n",
    "\n",
    "Due to the confinement of color charge at low energies, particles with color charge (i.e. gluons and quarks) form\n",
    "bundles of color-neutral particles during the hadronization and parton shower processes after the hard scattering.\n",
    "These color-neutral particles are referred to as jet constituents when clustered into jets. For each jet the\n",
    "four-momenta of the first 200 jet constituents (sorted by momentum) are stored.\n",
    "\n",
    "The training dataset is saved in a `HDF` file and loaded below. In this notebook the dataset is represented as `pandas`\n",
    "data frame. The components of the four vectors are saved in columns with names `E_i`, `PX_i`, `PY_i`, `PZ_i` where `i`\n",
    "is a number that runs from $0$ to $199$. The column `is_signal_new` is the label that tells us whether a jet originates\n",
    "from a top quark decay (if `signal_new` has the value $1$) or from a gluon (if `signal_new` has the value `0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d0d80",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, make sure that all relevant packages are installed\n",
    "# This should tell you that everything is already installed\n",
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from plotfunctions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,7)\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "# TODO adapt paths!\n",
    "df_train = pd.read_hdf('../data/train.h5', 'table', stop=300000)\n",
    "df_val = pd.read_hdf('../data/val.h5', 'table', stop=50000)\n",
    "df_test = pd.read_hdf('../data/train.h5', 'table', start=300000, stop=350000)\n",
    "df_secret = pd.read_hdf('../data/test_without_truth_100k.h5', 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63442f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eaa40a",
   "metadata": {},
   "source": [
    "First we want to look at the distributions of some kinematic variables. All events in the training dataset\n",
    "are labeled. Hence we can compare the distributions of top jets and gluon jets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe0e13f",
   "metadata": {},
   "source": [
    "- **Task 1.2.** Plot the distributions for the transverse momentum $p_{\\mathrm{T}}$ and the invariant mass\n",
    "  $m_{\\mathrm{inv}}$ of the jet, calculated with the 200 jet constituents with the highest $p_{\\mathrm{T}}$. The code\n",
    "  has already been implemented. Compare the distributions for jets originating from top quarks and for jet originating\n",
    "  from gluons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jet_pt_column(df):\n",
    "    px = np.sum([df['PX_{0:d}'.format(i)] for i in range(200)], axis=0)\n",
    "    py = np.sum([df['PY_{0:d}'.format(i)] for i in range(200)], axis=0)\n",
    "    df['Pt'] = np.linalg.norm([px, py], axis=0)\n",
    "\n",
    "\n",
    "def add_inv_mass_column(df):\n",
    "    e = np.sum([df['E_{0:d}'.format(i)] for i in range(200)], axis=0)\n",
    "    px = np.sum([df['PX_{0:d}'.format(i)] for i in range(200)], axis=0)\n",
    "    py = np.sum([df['PY_{0:d}'.format(i)] for i in range(200)], axis=0)\n",
    "    pz = np.sum([df['PZ_{0:d}'.format(i)] for i in range(200)], axis=0)\n",
    "    df['MInv'] = np.sqrt(np.power(e, 2) - np.power(np.linalg.norm([px, py, pz], axis=0), 2))\n",
    "\n",
    "\n",
    "# Add additional feature columns to the data frames here\n",
    "for df in [df_train, df_val, df_test, df_secret]:\n",
    "    add_jet_pt_column(df)\n",
    "    add_inv_mass_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963750a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_signal_background(df_train, 'Pt')\n",
    "fig, ax = plot_signal_background(df_train, 'MInv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9287fb",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9bd05",
   "metadata": {},
   "source": [
    "- **Task 1.3.** Look at the following distributions:\n",
    "\n",
    "  - The four-vector components of the constituents with indices $0$, $10$, $30$ and $70$ (indicating that the\n",
    "    jet constituent is that with the highest, tenth-highest, ... $p_{\\mathrm{T}}$).\n",
    " \n",
    "  - The transverse momentum of the constituents with indices $0$, $10$, $30$ and $70$.\n",
    "  \n",
    "  Also here, the code for adding the columns to the data frame and for plotting has already been implemented.\n",
    "  What differences do you observe for the distribution of top jets and gluon jets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 10, 30, 70]:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10.5))\n",
    "    fig, axes[0][0] = plot_signal_background(df_train, 'E_{}'.format(i), fig=fig, ax=axes[0][0])\n",
    "    fig, axes[0][1] = plot_signal_background(df_train, 'PX_{}'.format(i), fig=fig, ax=axes[0][1])\n",
    "    fig, axes[1][0] = plot_signal_background(df_train, 'PY_{}'.format(i), fig=fig, ax=axes[1][0])\n",
    "    fig, axes[1][1] = plot_signal_background(df_train, 'PZ_{}'.format(i), fig=fig, ax=axes[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pt_constituent_column(df, i):\n",
    "    df['Pt_{0:d}'.format(i)] = np.linalg.norm(np.array([df_train['PX_{0:d}'.format(i)].values, df_train['PY_{0:d}'.format(i)].values]), axis=0)\n",
    "    \n",
    "for i in range(20):\n",
    "    add_pt_constituent_column(df_train, i)\n",
    "add_pt_constituent_column(df_train, 30)\n",
    "add_pt_constituent_column(df_train, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10.5))\n",
    "fig, axes[0][0] = plot_signal_background(df_train, 'Pt_0', fig=fig, ax=axes[0][0])\n",
    "fig, axes[0][1] = plot_signal_background(df_train, 'Pt_10', fig=fig, ax=axes[0][1])\n",
    "fig, axes[1][0] = plot_signal_background(df_train, 'Pt_30', fig=fig, ax=axes[1][0])\n",
    "fig, axes[1][1] = plot_signal_background(df_train, 'Pt_70', fig=fig, ax=axes[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76ff81",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57a58f3",
   "metadata": {},
   "source": [
    "A basic implementation for training a DNN has been prepared in the notebook.\n",
    "\n",
    "- **Task 1.4.** Familiarize yourself with how the model is built and extract the following information from the code:\n",
    "\n",
    "  - How many layers does this network have?\n",
    "  \n",
    "  - What is the reason for inserting the so-called dropout layers between the dense layers?\n",
    "  \n",
    "  - What activation functions are used?\n",
    "  \n",
    "  - What is the purpose of the loss function and which one is chosen for this task?\n",
    "  \n",
    "  - Where are the number of training epochs and the batch size defined? What is the meaning of these two parameters?\n",
    "  \n",
    "\n",
    "For answering the questions you can look at the official `keras` documentation pages of the used classes and methods:\n",
    "\n",
    "- [keras.Sequential class](https://keras.io/api/models/sequential/)\n",
    "\n",
    "- [keras.Input class](https://keras.io/api/layers/core_layers/input/)\n",
    "\n",
    "- [keras.layers.Dense class](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "- [keras.layers.Dropout class](https://keras.io/api/layers/regularization_layers/dropout/)\n",
    "\n",
    "- [keras.Model methods like compile and fit](https://keras.io/api/models/model_training_apis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [c.format(i) for i in range(20) for c in ['E_{}', 'PX_{}', 'PY_{}', 'PZ_{}']]\n",
    "data_train = df_train[input_features].values\n",
    "labels_train = df_train['is_signal_new'].values\n",
    "data_val = df_val[input_features].values\n",
    "labels_val = df_val['is_signal_new'].values\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(data_train.shape[1], )))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(name='loss'),\n",
    "              metrics=['accuracy', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "epochs = 10\n",
    "\n",
    "model_history = model.fit(data_train, labels_train, validation_data=(data_val, labels_val), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b03cfd",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846de0b3",
   "metadata": {},
   "source": [
    "- **Task 1.5.** Now perform the training. After having finished the training, plot the loss and the accuracy history.\n",
    "\n",
    "  - What do these curves tell you about the training?\n",
    "  \n",
    "  - How could over-training (e.g. over-fitting) be observed in these plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_accuracy(model_history)\n",
    "fig, ax = plot_loss(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b79114",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88197e91",
   "metadata": {},
   "source": [
    "Finally we want to evaluate the separation power of the DNN we constructed above. For that we use a test dataset with\n",
    "labeled jets. The network output value is evaluated for each jet in the dataset. Finally the distributions of the\n",
    "network output value for jets that are labeled as top jets and for jets that are labeled as gluon jets.\n",
    "\n",
    "An important measure for evaluate the separation power is the *ROC-AUC value* that is equal to the area under the\n",
    "*ROC curve*. The ROC curve is calculated as follows: Several cut values for the network output are considered. For each\n",
    "cut value events above that threshold are considered to be predicted as top quark jets and events below that threshold\n",
    "are considered to be predicted as gluon jets. Following these assumptions the true positive rate\n",
    "$$\n",
    "  \\mathrm{TPR} = \\frac{\\mathrm{top\\,jets\\,above\\,cut}}{\\mathrm{top\\,jets}}\n",
    "$$\n",
    "and the false positive rate\n",
    "$$\n",
    "  \\mathrm{FPR} = \\frac{\\mathrm{gluon\\,jets\\,above\\,cut}}{\\mathrm{gluon\\,jets}}\n",
    "$$\n",
    "are calculated. Here, the true positive rate is called *signal efficiency*, while 1 minus the false positive rate is\n",
    "callsed *background rejection*. For each cut value these two rates form a point of the ROC curve. The ROC-AUC value\n",
    "is simply obtained by computing the area that is included by the ROC curve and the two axes of the coordinate system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb05b5",
   "metadata": {},
   "source": [
    "- **Task 1.6.** Look at the distributions of the network output value and the ROC curve. What do these curves tell you\n",
    "  about the network's ability to separate jets originating from a top quark from jets originating from a gluon? How\n",
    "  would you rate the discrimination power of the given network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = df_test[input_features].values\n",
    "labels_test = df_test['is_signal_new'].values\n",
    "labels_predicted = model.predict(data_test, verbose=1)\n",
    "fig, ax = plot_network_output(data_test, labels_test, labels_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1390ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_roc_curve(labels_test, labels_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420d818",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663b373",
   "metadata": {},
   "source": [
    "- **Task 1.7.** Imagine how you can improve the network architecture in order to reach a higher ROC-AUC value. Test\n",
    "  your ideas by modifying the present code in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e49c8f",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for DNN machine learning challenge\n",
    "def predict_for_challenge(filename, df_secret, model, input_features):\n",
    "    data_secret = df_secret[input_features].values\n",
    "    labels_predicted = model.predict(data_secret, verbose=1)\n",
    "    np.save(filename, labels_predicted)\n",
    "\n",
    "\n",
    "# Change filename if necessary\n",
    "predict_for_challenge('submission_predictions/group_xxxx_predictions_dnn_name.npy', df_secret, model, input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd07f0",
   "metadata": {},
   "source": [
    "## 2. Top tagging using convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53f795",
   "metadata": {},
   "source": [
    "We will now try a different approach to tagging these top quarks, namely image recognition. The shape of a particle\n",
    "physics detector like ATLAS or CMS is basically a cylinder. The surface of the cylinder can be unrolled along the\n",
    "radial ($\\phi$) and longitudinal ($\\eta$) coordinates. This surface is a rectangle and can be divided into pixels.\n",
    "Detected jet constituents can be filled into these pixels where the energies of the constituents can be transformed\n",
    "into intensities.\n",
    "\n",
    "For the purpose of this top tagging exercise jet images are provided which were already preprocessed to appear\n",
    "homogeneous. How these images are processed will be described during the tutorial. (Note: A single jet covers only a\n",
    "small part of the whole detector cylinder surface, hence needs to be cut and rotated appropriately to yield comparable\n",
    "jet images.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5349b61",
   "metadata": {},
   "source": [
    "- **Task 2.1.** Plot some jet images with the provided code. This also produces an overlay of many jet images. What\n",
    "  differences between top jet and gluon jet images do you observe? How can you explain these differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from plotfunctions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,7)\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "# TODO adapt paths!\n",
    "df_train = pd.read_hdf('../data/train_img.h5', 'table', stop=50000)\n",
    "df_val = pd.read_hdf('../data/val_img.h5', 'table', stop=20000)\n",
    "df_test = pd.read_hdf('../data/train_img.h5', 'table', start=100000, stop=120000)\n",
    "df_secret = pd.read_hdf('../data/test_without_truth_img_100k.h5', 'table', stop=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6962ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_overlayed_jet_images(df_train, 'top')\n",
    "fig, ax = plot_overlayed_jet_images(df_train, 'gluon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f353e22",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519c3a1",
   "metadata": {},
   "source": [
    "Image recognition works with a special type of neural networks, so-called *convolutional neural networks* (CNN). These\n",
    "networks have special convolutional layers which essentially convolute the pixelated jet images with learned filters.\n",
    "These filters can for example learn to detect edges, or sharpen or blur the images or even detect certain objects\n",
    "within the full picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8334424f",
   "metadata": {},
   "source": [
    "- **Task 2.2.** The notebook contains code that is needed to prepare the dataset for training and that defines a CNN\n",
    "  architecture. What are the functions of the convolutional layer, the pooling layer and the flatten layer? Train th\n",
    "  network and look at the evaluation plots.\n",
    "\n",
    "  For answering the questions you can look at the official `keras` documentation pages of the used classes and methods:\n",
    "\n",
    "  - [keras.layers.Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
    "\n",
    "  - [keras.layers.MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/)\n",
    "\n",
    "  - [keras.layers.Flatten](https://keras.io/api/layers/reshaping_layers/flatten/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9126374",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Write down your solution here.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_training(df):\n",
    "    pixels = ['img_{0:d}'.format(i) for i in range(1600)]\n",
    "    data = np.expand_dims(np.expand_dims(df[pixels].values, axis=-1).reshape(-1, 40, 40), axis=-1)\n",
    "    if 'is_signal_new' in df:\n",
    "        labels = df['is_signal_new'].values\n",
    "    else:\n",
    "        labels = None\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "data_train, labels_train = reshape_for_training(df_train)\n",
    "data_val, labels_val = reshape_for_training(df_val)\n",
    "data_test, labels_test = reshape_for_training(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca622f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(data_train.shape[1], data_train.shape[2], data_train.shape[3])))\n",
    "model.add(keras.layers.Conv2D(4, (4, 4), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(name='loss'),\n",
    "              metrics=['accuracy', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "epochs = 10\n",
    "\n",
    "model_history = model.fit(data_train, labels_train, validation_data=(data_val, labels_val), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predicted = model.predict(data_test, verbose=1)\n",
    "\n",
    "fig, ax = plot_accuracy(model_history)\n",
    "fig, ax = plot_loss(model_history)\n",
    "fig, ax = plot_roc_curve(labels_test, labels_predicted)\n",
    "fig, ax = plot_network_output(data_test, labels_test, labels_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for CNN machine learning challenge\n",
    "def predict_for_cnn_challenge(filename, df_secret, model):\n",
    "    data_secret, _ = reshape_for_training(df_secret)\n",
    "    labels_predicted = model.predict(data_secret, verbose=1)\n",
    "    np.save(filename, labels_predicted)\n",
    "\n",
    "\n",
    "# Change filename if necessary\n",
    "predict_for_cnn_challenge('submission_predictions/group_xxxx_predictions_cnn_name.npy', df_secret, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0912ae",
   "metadata": {},
   "source": [
    "## 3. Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c345924",
   "metadata": {},
   "source": [
    "Your task is to try to construct the best neural network architecture to achieve the best ROC-AUC values possible.\n",
    "  \n",
    "  - Prepare your best performing NNs (at most 3). Use the code cells at the end of the two exercises 1 and 2 that\n",
    "    contain the functions `predict_for_cnn_challenge` or respectively `predict_for_dnn_challenge`. These functions\n",
    "    take a model (and in the case of DNNs the list of input features), evaluate the predictions on a secret test\n",
    "    dataset and save the predictions to a `npy` file in the folder `submission_predictions`. Insert a name for your\n",
    "    group into the filename. If you train more than one network also insert a name. This filename will label your\n",
    "    submitted predictions for the ranking.\n",
    "\n",
    "  - Upload your `.npy` files with the predicted classes to moodle.\n",
    "  \n",
    "  - The predicted labels you submitted will be compared with the true labels of the jets.\n",
    "\n",
    "  - The winner will be announced in class on January 10th and will be rewarded an epic prize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169c769",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
